{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ æƒ³çŸ¥é“åŒ—äº¬çš„å¤©æ°”?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"åŸå¸‚\"],\n",
    "    template=\"ä½ æƒ³çŸ¥é“{åŸå¸‚}çš„å¤©æ°”?\",\n",
    ")\n",
    "print(prompt.format(åŸå¸‚=\"åŒ—äº¬\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ æƒ³çŸ¥é“åŒ—äº¬çš„29/04/2024, 16:15:44å¤©æ°”?\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def _getdate():\n",
    "    now =  datetime.now()\n",
    "    return now.strftime('%d/%m/%Y, %H:%M:%S')\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"åŸå¸‚\",\"æ—¶é—´\"],\n",
    "    template=\"ä½ æƒ³çŸ¥é“{åŸå¸‚}çš„{æ—¶é—´}å¤©æ°”?\",\n",
    ")\n",
    "partial_prompt = prompt.partial(åŸå¸‚=\"åŒ—äº¬\")\n",
    "print(partial_prompt.format(æ—¶é—´=_getdate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜:ä½ æ˜¯è°\n",
      "å›ç­”:å¸…å“¥ï¼Œæˆ‘æ˜¯å¼ ä¸‰\n",
      "\n",
      "é—®é¢˜:ä»Šå¤©å‘¨å‡ \n",
      "å›ç­”:å¸…å“¥ï¼Œä»Šå¤©å‘¨ä¸€\n",
      "\n",
      "é—®é¢˜:ä»Šå¤©å¤©æ°”å’‹æ ·\n",
      "å›ç­”:å¸…å“¥ï¼Œä»Šå¤©æœ‰é›¨\n",
      "\n",
      "é—®é¢˜:ä½ ä»Šå¹´å¤šå¤§\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\":\"ä½ æ˜¯è°\",\n",
    "        \"answer\":\"å¸…å“¥ï¼Œæˆ‘æ˜¯å¼ ä¸‰\"\n",
    "    },\n",
    "    {\n",
    "        \"question\":\"ä»Šå¤©å‘¨å‡ \",\n",
    "        \"answer\":\"å¸…å“¥ï¼Œä»Šå¤©å‘¨ä¸€\"\n",
    "    },\n",
    "    {\n",
    "        \"question\":\"ä»Šå¤©å¤©æ°”å’‹æ ·\",\n",
    "        \"answer\":\"å¸…å“¥ï¼Œä»Šå¤©æœ‰é›¨\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\",\"answer\"],template=\"é—®é¢˜:{question}\\nå›ç­”:{answer}\")\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"é—®é¢˜:{question}\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(question=\"ä½ ä»Šå¹´å¤šå¤§\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¸…å“¥ï¼Œæˆ‘ä»Šå¹´24å²ï¼ ğŸ¤©'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "ollama = Ollama(base_url='http://10.0.21.170:11434', model=\"llama3\")\n",
    "ollama.predict(prompt.format(question=\"ä½ ä»Šå¹´å¤šå¤§\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1må†·æ·¡AI\u001b[0m\n",
      "Params: {}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from typing import Optional,List,Any\n",
    "\n",
    "class å†·æ·¡AI(LLM):\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"å†·æ·¡AI\"\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"å¼‚å¸¸\")\n",
    "        pd = prompt.find(\"å—\")\n",
    "        if pd>=0:\n",
    "            return prompt[0:pd]+\"ã€‚\"\n",
    "        return \"å“¦\"\n",
    "    \n",
    "llm = å†·æ·¡AI()\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ã€‚'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"ä½ å¥½å—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'åƒäº†ã€‚'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"åƒäº†å—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å“¦'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"ä½ ä¸ºä»€ä¹ˆå¯¹æˆ‘è¿™ä¹ˆå†·æ·¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä½ æ˜¯å‚»é€¼ã€‚'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"ä½ æ˜¯å‚»é€¼å—\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
